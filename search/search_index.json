{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#some-general-reading","title":"Some general reading ...","text":"<p>Question</p> <p>What is data science?</p> <p>Data science is an interdisciplinary field that involves the extraction of insights from data using statistical, computational, and machine learning techniques. Data science involves the entire process of collecting, processing, analyzing, and interpreting data to solve complex problems and make data-driven decisions.</p> <p>Question</p> <p>Why is data science important?</p> <p>Data science is important because it allows us to make sense of vast amounts of data that are generated every day. By extracting insights from data, we can identify patterns, trends, and relationships that can inform business decisions, scientific research, and public policy. Data science also plays a critical role in developing and improving machine learning algorithms that power many modern technologies.</p> <p>Question</p> <p>What are some common applications of data science?</p> <p>Data science is used in a wide range of industries and fields, including business, healthcare, finance, marketing, and scientific research. Some common applications of data science include fraud detection, customer segmentation, predicting disease outbreaks, personalized recommendations, and image and speech recognition.</p> <p>Question</p> <p>What are data science tools?</p> <p>Data science tools are software applications, libraries, and frameworks that are used to facilitate the various tasks involved in data science, such as data manipulation, data analysis, machine learning, and data visualization.</p>"},{"location":"#session-1","title":"Session 1","text":"<pre><code>    %%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'showBranches': true, 'showCommitLabel':true,'mainBranchName': 'session1'}} }%%\n\n    gitGraph\n       checkout session1\n       commit id: \"Git &amp; Version control\"\n       commit id: \"Python package management\"\n       branch foo\n       checkout foo\n       commit id: \"Anaconda + Conda\"\n       commit id: \"pip\"\n       commit id: \"poetry\"\n       checkout session1\n       merge foo\n       commit id: \"Notebooks\"\n</code></pre>"},{"location":"#session-2","title":"Session 2","text":"<pre><code>    %%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'showBranches': true, 'showCommitLabel':true,'mainBranchName': 'session2'}} }%%\n\n    gitGraph\n       commit id: \"1\"\n       branch docker\n       checkout docker\n       commit id: \"postgres\"\n       commit id: \"pgadmin\"\n       commit id: \"metabase\"\n       checkout session2\n       merge docker\n       commit id: \"2\"\n       branch docker-compose\n       checkout docker-compose\n       commit id: \"all at once\"\n       checkout session2\n       merge docker-compose\n\n\n</code></pre>"},{"location":"#session-3","title":"Session 3","text":"<p>This session will be oriented around basic data visualization libraries &amp; framework.</p> <pre><code>    %%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'showBranches': true, 'showCommitLabel':true,'mainBranchName': 'session3'}} }%%\n\n    gitGraph\n       commit id: \"Data viz libraries\"\n       branch libraries\n       checkout libraries\n       commit id: \"matplotlib\"\n       commit id: \"seaborn\"\n       checkout session3\n       merge libraries\n       commit id: \"Data viz framework\"\n       branch framework\n       checkout framework\n       commit id: \"plotly dash\"\n       checkout session3\n       merge framework\n\n\n</code></pre>"},{"location":"docker/","title":"Docker","text":""},{"location":"docker/#introduction","title":"Introduction","text":"<p>Docker is a software platform that allows developers to package, distribute, and run applications in a containerized  environment. Containers are lightweight, portable, and self-contained environments that can run almost anywhere,  from a developer's laptop to a cloud-based infrastructure.</p>"},{"location":"docker/#what-is-containerization","title":"What is containerization ?","text":""},{"location":"docker/#key-concepts-components","title":"Key concepts &amp; components","text":"<p>Tip</p> <p>The best way to be familiar with docker is to practice, also they provide a great documentation</p>"},{"location":"docker/#1-dockerfile","title":"1. Dockerfile","text":"<p>A Dockerfile is a text file that contains instructions on how to build a Docker image. The Docker image is a binary file  that contains everything needed to run an application, including the code, libraries, and dependencies. </p>"},{"location":"docker/#2-docker-image","title":"2. Docker image","text":"<p>A Docker image is a snapshot of a container, which includes the application code, libraries, and dependencies.  Images can be built from a Dockerfile or pulled from a public or private Docker registry.</p>"},{"location":"docker/#3-docker-registry","title":"3. Docker registry","text":"<p>A Docker registry is a repository for storing and sharing Docker images. Docker Hub is the most popular public Docker  registry, but you can also use private registries for your organization's images.</p>"},{"location":"docker/#4-docker-container","title":"4. Docker container","text":"<p>A Docker container is a lightweight, standalone executable package that includes everything needed to run an  application, including the application code, libraries, and dependencies. Containers are isolated from the host  system and from other containers, making them a secure way to run applications.</p>"},{"location":"docker/#5-docker-compose","title":"5. Docker Compose","text":"<p>Docker Compose is a tool for defining and running multi-container Docker applications. With Docker Compose, you can define the services that make up your application, their configuration, and the network they should use to communicate with each other.</p>"},{"location":"docker/#6-docker-swarm","title":"6. Docker Swarm","text":"<p>Info</p> <p>It's not very common to use it in a production environment, the standard is to use kubernetes</p> <p>Docker Swarm is a native clustering and orchestration tool for Docker. With Swarm, you can create and manage a cluster  of Docker nodes, and deploy and manage Docker services across the cluster.</p>"},{"location":"docker/#commands-recap","title":"Commands recap","text":"<p>Tip</p> <p>Once again, you don't need to remind all the commands, just practice and go through the documentation ! </p> Command Description docker run Run a container docker ps List running containers docker images List available images docker build Build an image from a Dockerfile docker push Push an image to a remote registry docker pull Pull an image from a remote registry docker stop Stop a running container docker rm Remove a container docker rmi Remove an image docker exec Execute a command in a running container docker logs View the logs of a container"},{"location":"git/","title":"Git","text":""},{"location":"git/#what-we-have-seen-last-week","title":"What we have seen last week","text":"<ul> <li>git concept &amp; basic commands</li> <li>branches</li> <li>pull request &amp; review process</li> <li>simple feature branch workflow</li> <li>ci/cd introduction</li> <li>zoom on github</li> </ul>"},{"location":"git/#commands-recap","title":"Commands recap","text":"<p>Tip</p> <p>You don't need to remind all the commands, just practice and go through the documentation or man page !</p> Command Description <code>git init</code> Initialize a git repository <code>git add &lt;file_name&gt;</code> Add a file to staging area <code>git commit -m \"an explicit message\"</code> Commit changes with an explicit message <code>git push origin &lt;branch_name&gt;</code> Push changes to a remote branch <code>git branch &lt;branch_name&gt;</code> Create a new branch <code>git checkout &lt;branch_name&gt;</code> Switch to a branch <code>git checkout -b &lt;branch_name&gt;</code> Create and switch to a new branch"},{"location":"git/#branch-coding-workflow","title":"Branch &amp; coding workflow","text":"<p>Danger</p> <p>Reminder: Don't code on master branch</p>"},{"location":"git/#the-minimal-workflow-can-be-used-when-coding-alone","title":"The minimal workflow, can be used when coding alone","text":"<pre><code>---\ntitle: Minimal workflow\n---\n%%{init: { 'logLevel': 'debug', 'theme': 'base' } }%%\ngitGraph\n   commit\n   commit\n   branch develop\n   checkout develop\n   commit\n   commit\n   checkout main\n   merge develop\n   commit\ncommit</code></pre>"},{"location":"git/#a-basic-feature-branch-workflow","title":"A basic feature branch workflow","text":"<pre><code>---\ntitle: Basic feature branch workflow\n---\n    %%{init: { 'logLevel': 'debug', 'theme': 'base' } }%%\n    gitGraph\n       commit id: \"1\"\n       commit id: \"2\"\n       branch feature_1\n       checkout feature_1\n       commit id: \"3\"\n       checkout main\n       commit id: \"4\"\n       checkout main\n       branch feature_2\n       checkout feature_2\n       commit id: \"5\"\n       checkout main\n       commit id: \"6\"\n       checkout feature_1\n       commit id: \"7\"\n       checkout main\n       merge feature_1 id: \"customID\" tag: \"customTag\" type: REVERSE\n       checkout feature_2\n       commit id: \"8\"\n       checkout main\n       commit id: \"9\"</code></pre>"},{"location":"git/#best-practices","title":"Best practices","text":""},{"location":"git/#make-single-purpose-small-commits","title":"Make single-purpose &amp; small commits","text":"<p>By creating small commits, it helps everyone in a team to understand what have been done. Also, it's easier to revert a small change in case of bug.</p>"},{"location":"git/#share-only-what-is-necessary-add-gitignore-to-you-repository","title":"Share only what is necessary, add .gitignore to you repository","text":"<p>Info</p> <p><code>.gitignore</code> list all the files and folder that must not be tracked</p> <p>Example</p>"},{"location":"git/#ginignore-simple-example","title":"<code>.ginignore</code> simple example :","text":"<pre><code>__pycache__/\nvenv/\ndata/\ndownload/\nlog.txt\nany_file_you_want_to_exclude.any_extension\n</code></pre>"},{"location":"git/#commit-often-branch-frequently","title":"Commit often &amp; branch frequently","text":"<p>Prefer short-term branch, this will improve the traceability and highly simplify the code review process. Try to not include large number of change in the same branch, and avoid unrelated changes.</p> <p>Tip</p> <p>It's better to commit something un-perfect than nothing  </p>"},{"location":"git/#write-detailed-commit-message-but-short","title":"Write detailed commit message (but short !)","text":"<p>When reading a commit message, anyone should be able to understand what have been done. In general, try to explain what changed from previous code and why.</p> <p>Some good examples: </p> <ul> <li>Change number of epochs from 20 to 40</li> <li>Filter samples that contains null values</li> <li>Change unit from miles to kilometers in compute_distance method</li> </ul> <p>Some bad examples:</p> <ul> <li>Update file1, file2</li> <li>A modification</li> </ul>"},{"location":"python_package_management/","title":"Python package management","text":""},{"location":"python_package_management/#introduction","title":"Introduction","text":"<p>Pip, Anaconda, and Poetry are all package managers for Python, but they have different features and use cases.</p> <p>Info</p> <p>For local development, you can choose between pip &amp; conda depending on your preferences.  In a company, you'll use the one used by the other developers</p>"},{"location":"python_package_management/#pip","title":"Pip","text":"<p>Pip is the default package manager for Python and is used to install and manage Python packages from the Python Package Index (PyPI). Pip is included with Python, and you can use it to install packages globally or in a virtual environment. Pip is simple to use and is suitable for most Python projects.</p>"},{"location":"python_package_management/#anaconda","title":"Anaconda","text":"<p>Anaconda is a distribution of Python that includes many scientific computing packages and tools, such as NumPy, SciPy, and Jupyter notebooks. Anaconda comes with its package manager called conda, which is similar to pip but also includes features for managing non-Python packages and managing virtual environments. Anaconda is particularly useful for data science and machine learning projects because it includes many packages commonly used in those fields.</p>"},{"location":"python_package_management/#poetry","title":"Poetry","text":"<p>Poetry is a newer package manager for Python that aims to simplify dependency management and package distribution. Poetry includes features for managing virtual environments, specifying dependencies and versions, and packaging your project as a distributable package. Poetry is designed to work well with modern Python projects that use tools like Pytest and Black.</p> <p>In summary, if you're working on a simple Python project, pip should suffice. If you're working on a data science or machine learning project, Anaconda might be a better choice. If you're working on a modern Python project that requires advanced dependency management and package distribution, Poetry is worth considering. Ultimately, the choice of package manager depends on your project's requirements and your personal preference.</p>"},{"location":"python_package_management/#commands-recap","title":"Commands recap","text":""},{"location":"python_package_management/#virtual-environment-creation","title":"Virtual environment creation","text":"<p>Warning</p> <ul> <li>You must use virtual env to manage your python projects, basically it will allow you : </li> <li>to prevent version conflicts</li> <li>to create reproducible and easy to install project</li> </ul> <p>There are many way to create virtual env depending on your setup, one you can use : <code>python3 -m venv env_name</code></p>"},{"location":"python_package_management/#pip-usage","title":"Pip usage","text":"<ul> <li>Activate a virtual environment : <code>conda activate env_name</code></li> <li>Install a package : <code>pip install package_name</code></li> <li>Install packages from requirements file : <code>pip install -r requirements.txt</code></li> </ul>"},{"location":"python_package_management/#conda-usage","title":"Conda usage","text":"<ul> <li>Activate a virtual environment : <code>conda activate env_name</code></li> <li>Install a package : <code>conda install package_name</code></li> <li>Install packages from requirements file : <code>conda install --file requirements.txt</code></li> </ul>"},{"location":"practice/docker/","title":"Docker","text":""},{"location":"practice/docker/#docker-in-practice","title":"Docker in practice","text":"<p>Let's setup a local environment with the following components : </p> <ul> <li>A database : postgresql</li> <li>An database administration platform : pgadmin</li> <li>A Business intelligence app : metabase</li> </ul> <p>Danger</p> <p>This is a local setup, in a real life project, you'll not host your database in a docker container Also, metabase use a database to store its metadata, by default it comes with an sqllite, which must be replaced by another external database like postgres or mysql</p>"},{"location":"practice/docker/#docker-a-simple-way-to-setup-your-local-environment","title":"Docker, a simple way to setup your local environment","text":"<p>You can deploy any application using a very short command... with docker !</p>"},{"location":"practice/docker/#deploy-a-database","title":"Deploy a database","text":"<pre><code>docker run -d \\\n--name postgres \\ \n-p 5432:5432 \\\n-e POSTGRES_PASSWORD=password \\\n-v postgres:/var/lib/postgresql/data \\ \npostgres:15.2\n</code></pre> <p>Let's decompose this command : </p> Argument Description <code>docker run</code> Command to start a new container <code>-d</code> Runs the container in the background (detached mode) <code>--name postgres</code> Assigns the name <code>postgres</code> to the new container <code>-p 5432:5432</code> Maps port 5432 on the host machine to port 5432 in the container <code>-e POSTGRES_PASSWORD=password</code> Sets an environment variable <code>POSTGRES_PASSWORD</code> with the value <code>password</code> inside the container <code>-v postgres:/var/lib/postgresql/data</code> Mounts a Docker volume named <code>postgres</code> to the container directory <code>/var/lib/postgresql/data</code> <code>postgres:15.2</code> Specifies the name and tag of the PostgreSQL Docker image to use for the new container <p>Now you've a running postgres instance which is listening on port 5432, you can connect to it using <code>psql</code> or any client.</p> <p>You can check it by running <code>docker ps</code> or directly in docker desktop if you prefer the UI.</p> <p>You will have an output like this :  <pre><code>CONTAINER ID   IMAGE           COMMAND                  CREATED         STATUS         PORTS                    NAMES\n3ca9e24601b5   postgres:15.2   \"docker-entrypoint.s\u2026\"   5 seconds ago   Up 4 seconds   0.0.0.0:5432-&gt;5432/tcp   postgres\n</code></pre></p> <p>Tip</p> <p>It's better to use the cli (the commands) instead of the UI, it will help you to become more familiar with docker</p> <p></p>"},{"location":"practice/docker/#deploy-pgadmin","title":"Deploy pgadmin","text":"<p>For the exercise, let's say you want setup a web client to monitor and administrate your database. Let's deploy pg admin !</p> <pre><code>docker run \\\n-p 5050:80 \\\n-e \"PGADMIN_DEFAULT_EMAIL=email@example.com\" \\\n-e \"PGADMIN_DEFAULT_PASSWORD=password\" \\\n-d dpage/pgadmin4:latest\n</code></pre> <p>To be sure you understand... let's describe the command again</p> Argument Description <code>docker run</code> Command to start a new container <code>-p 5050:80</code> Maps port 80 inside the container to port 5050 on the host machine <code>-e \"PGADMIN_DEFAULT_EMAIL=email@example.com\"</code> Sets an environment variable <code>PGADMIN_DEFAULT_EMAIL</code> with the value <code>email@example.com</code> inside the container <code>-e \"PGADMIN_DEFAULT_PASSWORD=password\"</code> Sets an environment variable <code>PGADMIN_DEFAULT_PASSWORD</code> with the value <code>password</code> inside the container <code>-d</code> Runs the container in the background (detached mode) <code>dpage/pgadmin4:latest</code> Specifies the name and tag of the pgAdmin4 Docker image to use for the new container <p>Info</p> <p>You'll notice that this time, the version is set using :latest, this is a tag that refers to the most recent version of a Docker image. It's better to specify a version like dpage/pgadmin4:4.32 this would ensure that you always use the same version of the image, regardless of whether a new \"latest\" version is released.</p> <p> Now, if you go to localhost:5050 you'll be able to access the pg admin interface. </p> <p></p> <p>If you perform a <code>docker ps</code> you'll see two containers, one for postgres and one for pgadmin</p> <pre><code>CONTAINER ID   IMAGE               COMMAND                  CREATED         STATUS         PORTS                                       NAMES\n3ca9e24601b5   postgres:15.2      \"docker-entrypoint.s\u2026\"   5 minutes ago   Up 5 minutes   0.0.0.0:5432-&gt;5432/tcp, :::5432-&gt;5432/tcp   postgres\na08f7a258dbf   dpage/pgadmin4:4.23 \"/entrypoint.sh\"         5 minutes ago   Up 5 minutes   0.0.0.0:5050-&gt;80/tcp, :::5050-&gt;80/tcp       pgadmin\n</code></pre> <p></p>"},{"location":"practice/docker/#deploy-a-bi-platform-metabase","title":"Deploy a BI platform, metabase","text":"<p>There are many BI platforms, however only few are open-source. In addition, metabase can be deployed in seconds...  with docker.  <pre><code>docker run -d -p 3000:3000 --name metabase metabase/metabase\n</code></pre>  If you perform a docker ps you'll see 3 containers :  <pre><code>CONTAINER ID   IMAGE               COMMAND                  CREATED         STATUS         PORTS                                       NAMES\n3ca9e24601b5   postgres:15.2      \"docker-entrypoint.s\u2026\"   5 minutes ago   Up 5 minutes   0.0.0.0:5432-&gt;5432/tcp, :::5432-&gt;5432/tcp   postgres\na08f7a258dbf   dpage/pgadmin4:4.23 \"/entrypoint.sh\"         5 minutes ago   Up 5 minutes   0.0.0.0:5050-&gt;80/tcp, :::5050-&gt;80/tcp       pgadmin\ncc8a7f165c43   metabase/metabase:0.45 \"/app/run_metabase.s\u2026\"  5 seconds ago    Up 4 seconds    0.0.0.0:3000-&gt;3000/tcp                     metabase\n</code></pre></p> <p> Metabase is now accessible on localhost:3000. You'll have to wait a bit of time to be able to access it and have  a page like this:  </p> <p></p> <p></p>"},{"location":"practice/docker/#all-together-docker-compose","title":"All together, docker-compose","text":"<p>We've seen how to run single container application, using separated commands, but this is not very convenient... As previously mentioned, there is a way to manage multi-container applications : <code>docker-compose</code></p> <p>Info</p> <p>You will not have to learn commands for both <code>docker</code> and <code>docker-compose</code>, basically you'll find the  same commands. Ex : <code>docker ps</code> become <code>docker-compose ps</code></p> <p>In order to use docker-compose, you need to write a <code>docker-compose.yml</code> file that describe each container you want to  deploy.</p> <p>Here is an example of a file describing our 3 previously deployed application : </p> <p></p> <pre><code>version: \"3\"\nservices:\npostgres:\nimage: postgres:14.2-alpine\nrestart: always\nenvironment:\nPOSTGRES_PASSWORD: postgres\nPOSTGRES_USER: postgres\nPOSTGRES_HOST: \"0.0.0.0\"\nvolumes:\n- postgres:/var/lib/postgresql/data\npgadmin:\nimage: dpage/pgadmin4:4.23\nenvironment:\nPGADMIN_DEFAULT_EMAIL: admin@pgadmin.com\nPGADMIN_DEFAULT_PASSWORD: password\nPGADMIN_LISTEN_PORT: 80\nports:\n- 8080:80\nvolumes:\n- pgadmin:/var/lib/pgadmin\ndepends_on:\n- postgres\nmetabase:\nimage: metabase/metabase\nports:\n- \"3000:3000\"\nrestart: always\nvolumes:\npostgres:\npgadmin:\n</code></pre> <p>Inside the folder where you <code>docker-compose.yml</code> file is located, simply run <code>docker-compose up -d</code>.</p> <p>Info</p> <ul> <li>The version \"3\" at the beginning of the file indicates that this is a Docker Compose file written in version 3 syntax.</li> <li>The file defines three services: postgres, pgadmin, and metabase.</li> <li>The postgres service runs the official PostgreSQL 14.2-alpine image, which is a lightweight version of the PostgreSQL database running on the Alpine Linux distribution. It sets environment variables for the database user and password, and also specifies a volume to store the database data.</li> <li>The pgadmin service runs the dpage/pgadmin4:4.23 image, which is a web-based administration tool for PostgreSQL. It sets environment variables for the default email and password, and exposes port 8080 on the host machine to port 80 on the container. It also specifies a volume to store pgAdmin data, and depends on the postgres service to be running.</li> <li>The metabase service runs the metabase/metabase image, which is a business intelligence and analytics tool. It exposes port 3000 on the host machine to port 3000 on the container, and sets the restart policy to always.</li> <li>The volumes section defines two named volumes, postgres and pgadmin, which are used by the postgres and pgadmin services respectively to store data.</li> </ul>"}]}